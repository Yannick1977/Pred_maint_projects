{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sample time series dataset\n",
    "# You can replace this with your own time series data\n",
    "# Ensure that the data is in a NumPy array or a list\n",
    "time = np.arange(0, 10, 0.01)  # Time values from 0 to 10 with a step of 0.01\n",
    "signal = 2 * np.sin(2 * np.pi * 1 * time) + 1 * np.sin(2 * np.pi * 2 * time)\n",
    "\n",
    "# Plot the original time series\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, signal)\n",
    "plt.title('Original Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Perform the Fourier Transform\n",
    "fourier_transform = np.fft.fft(signal)\n",
    "frequencies = np.fft.fftfreq(len(signal), 0.01)  # Frequency values (assuming a sampling interval of 0.01)\n",
    "\n",
    "# Plot the magnitude of the Fourier Transform\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(frequencies, np.abs(fourier_transform))\n",
    "plt.title('Fourier Transform')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlim(0, 5)  # Limit the x-axis to show frequencies up to 5 Hz\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "def get_library_versions(libraries):\n",
    "    with open('../requirements.txt', 'w') as f:\n",
    "        for library in libraries:\n",
    "            try:\n",
    "                version = pkg_resources.get_distribution(library).version\n",
    "                f.write(f\"{library}=={version}\\n\")\n",
    "            except pkg_resources.DistributionNotFound:\n",
    "                print(f\"{library} is not installed\")\n",
    "\n",
    "# Liste des bibliothèques à vérifier\n",
    "libraries = [\"numpy\", \"pandas\", \"scikit-learn\", \"scipy\", \n",
    "             \"seaborn\", \"tensorflow\", \"keras\", \"matplotlib\", 'imblearn']\n",
    "\n",
    "get_library_versions(libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea7cf1",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../data/predictive_maintenance_A.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../Src/')\n",
    "\n",
    "from Function_preprocess import preprocess\n",
    "df = pd.read_csv(FILE_PATH, index_col='UDI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "def get_version(package_name):\n",
    "    try:\n",
    "        return pkg_resources.get_distribution(package_name).version\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        return \"Le package n'est pas installé\"\n",
    "\n",
    "print(get_version(\"keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65160d8c",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger le jeu de données Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Diviser le jeu de données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer une instance de LogisticRegression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Entraîner le modèle\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les classes pour l'ensemble de test\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Précision du modèle: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binariser les étiquettes dans un format one-vs-all pour l'utilisation avec roc_auc_score\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "y_pred_bin = logreg.predict_proba(X_test)\n",
    "\n",
    "# Calculer l'AUC pour chaque classe\n",
    "auc = roc_auc_score(y_test_bin, y_pred_bin, multi_class='ovr')\n",
    "\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-box==6.0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9751b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Charger les données\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = to_categorical(iris.target)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer et entraîner le modèle\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "# Utiliser le Deep Explainer SHAP\n",
    "background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "# Calculer les valeurs SHAP\n",
    "shap_values = explainer.shap_values(background)\n",
    "\n",
    "# Afficher le résumé du tracé\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=iris.feature_names, class_names=iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "os.chdir('..')\n",
    "\n",
    "from Src.config import configuration\n",
    "cfg = configuration.config_manager().get_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee652be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_transformer = './'+cfg.config_path.work_dir+'/transformer.pkl'\n",
    "ct_X_ = joblib.load(file_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "tab = np.array(['z', '0', '0', '0', '0', '0', '0', '0'])\n",
    "tab = pd.DataFrame(tab.reshape(1, -1), columns=ct_X_.feature_names_in_)\n",
    "#tab.columns = ct_X_.feature_names_in_\n",
    "#tab.columns = ['Type', 'Air temperature [K]', 'Process temperature [K]',\n",
    "#       'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]',\n",
    "#       'Difference temperature [K]', 'Power']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c218c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ct_X_.feature_names_in_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bbcec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
